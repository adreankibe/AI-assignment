# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b15XuasAqPGAI4qlrBfLmIrBE7vnc6NJ

doing the library imports
"""

from tensorflow import keras
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from keras.utils import to_categorical
from keras import models
from keras import layers, Sequential
from keras.layers import Dense, Flatten

"""importing our data set"""

from keras.datasets import imdb
(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)
data = np.concatenate((training_data, testing_data), axis=0)
targets = np.concatenate((training_targets, testing_targets), axis=0)

"""Data preparation
vectorization of every review so that every review is of the same size
"""

def vectorize(sequences, dimension = 10000):
  results = np.zeros((len(sequences),dimension))
  for i, sequence in enumerate(sequences):
    results[i, sequence] = 1
    return results

  data = vectorize(data)
  targets = np.array(targets).astype("float32")

"""split the data into testing and training"""

test_x = data[:10000]
test_y = targets[:10000]
train_x = data[10000:]
train_y = targets[10000:]

"""training model"""

model= Sequential()
model.add(layers.Dense(50, activation = "relu", input_shape=(10000, )))
model.add(layers.Dropout(0.3, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation="relu"))
model.add(layers.Dropout(0.2, noise_shape=None, seed=None))
model.add(layers.Dense(50, activation = "relu"))
model.add(layers.Dense(1, activation = "sigmoid"))
model.summary()

"""compile the model"""

model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['acc'])
model.fit(train_x, train_y, epochs = 5)